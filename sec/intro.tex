\section{Introduction}\label{sec:intro}

Modern research, in all respects, is highly dependent on the use of
data.~\cite{Womack2015} considers a stratified sample of several thousand
articles from leading journals across the natural sciences, and suggests that
perhaps as many as 80\% of all scientific articles published in 2014 utilised
research data directly. That article is one of many in an increasing body of
publications over the last decade that concern themselves with the state of
research data~\cite{Higman2019}, its utilisation and
openness~\cite{Aslam2017,Zuiderwijk2020}, and the importance of good
practices~\cite{Colavizza2020,Corti2019}. These publications, for the most part,
do not cater specifically to the increasingly popular concepts attached to
\emph{Big Data}, where the volume and variety of a data source should be
maximised~\cite{Batisti2019}. Instead, the focal point is in the quality of
research data as a resource, and as a mark of the associated research's
quality.~\cite{Stall2019} argues for the widespread use of a concept adopted
already in the geosciences, that research data should be \emph{Findable,
Accessible, Interoperable and Reusable} (FAIR) --- an acronym coined
in~\cite{Wilkinson2016}.

In tandem with this shift was the rise in the use of software to implement and
compute algorithms (including clustering), and so electronic data became
essential. As the size and complexity of research data increased, so did the
span of the field \emph{machine learning}. Machine learning is a loose term to
describe how a computer (machine) may learn (by use of statistics) from a
potentially large source of data, without following explicit instructions. Owing
in part to this broad definition, machine learning comprises a great deal of
techniques that were borne out of statistics, including regression,
classification and clustering, despite having lost its connection with the
statistics that underpin it, at least colloquially.

Healthcare modelling is one crucial (albeit broad) branch of research in which
decisions are increasingly being informed by data-driven
methodologies~\cite{Alexander2018,Belle2015,RiosZertuche2020}, often based
around machine learning techniques. Clustering is a long-standing and often-used
method in healthcare settings; its efficacy --- as a tool not only to expose
homogeneous partitions within a dataset, but to straightforwardly garner the
attention of non-technical stakeholders --- has proven it to be an essential
part of healthcare modelling research.

Regardless of the particular methods that are to be implemented, the quality of
a methodology must be evaluated as being `good' before it can be used in a real
world setting. The ways in which this evaluation is carried out is reliant on
both the methods themselves and the setting in which they are applied, but there
are some approaches used across research fields such as consensus by literature
or beating some rival method(s) according to a metric on a dataset.

This survey considers the literature surrounding these three components of
modern operational and mathematical research --- clustering, the evaluation of
algorithms, and healthcare modelling --- as well as their intersections. Given
the potentially vast nature of the literature under study, formulating a
reasonable slice that encompasses the state of the research is difficult. As
such, this survey utilises two approaches, setting the structure of the survey:

\begin{itemize}
    \item In Section~\ref{sec:review}, a review of a selection of representative
        and innovative publications from across the aforementioned research
        topics;
    \item In Section~\ref{sec:bibliometric}, a software-based bibliometric study
        of the literature from five leading academic publishers and preprint
        servers.
\end{itemize}
